#!/usr/bin/env python

import argparse
import numpy as np
import h5py
import bossdata
import tpcorr

import astropy.units as u

def calculate_corrections(obs_grp, wlen_grid, add_guiding_error=None, steps_per_exposure=5, seeing_wlen=5400.*u.Angstrom):

    # Precompute wlen ratio for wavelength dependent seeing adjustment
    wlen_ratio = (wlen_grid / seeing_wlen).si

    num_exposures = obs_grp.attrs['num_exposures']
    seeing = obs_grp['seeing'].value * u.arcsec
    if add_guiding_error:
        seeing = np.sqrt(seeing**2 + add_guiding_error**2)

    fiber_ids = obs_grp['fiber_ids'].value
    num_offset_targets = len(fiber_ids)

    # Initialize acceptance ratio grid
    corrections = np.empty(
        (num_exposures, num_offset_targets, len(wlen_grid), steps_per_exposure),
        dtype=float)

    # Loop over exposures
    for exp_index in range(num_exposures):

        offset = obs_grp[str(exp_index)]['offset'].value*u.arcsec
        offset_std = obs_grp[str(exp_index)]['offset_std'].value*u.arcsec

        seeing_exp = seeing[exp_index]
        # psf = sdss_25m.get_atmospheric_psf(seeing_wlen, seeing, gauss=False)
        # acceptance_model = sdss_25m.calculate_fiber_acceptance(psf)

        seeing_wlen_adjusted = seeing_exp*wlen_ratio**(-0.2)
        # acceptance_model_grid = map(tpcorr.acceptance_model.AcceptanceModel, seeing_wlen_adjusted)
        max_offset = 1.1/2.0*max(np.max(offset.to(u.arcsec)).value,
                                 np.max(offset_std.to(u.arcsec).value))

        for wlen_index in range(len(wlen_grid)):
            # Build acceptance model for this wavelength
            acceptance_model = tpcorr.acceptance_model.AcceptanceModel(
                seeing_wlen_adjusted[wlen_index], max_offset=max_offset)

            # Calculate the acceptance fractions for both sets of centroid offsets.
            acceptance = acceptance_model(offset[:,wlen_index,:].to(u.arcsec))
            acceptance_std = acceptance_model(offset_std[:,wlen_index,:].to(u.arcsec))
            
            # Calculate the acceptance fraction ratios, tabulated for each offset target, wavelength and time.
            # The ratio calculated this way gives the correction of eqn (13).
            corrections[exp_index,:,wlen_index,:] = acceptance_std / acceptance

    # Average the correction over each exposure time slice.
    return np.mean(np.mean(corrections, axis=-1), axis=0)

def save_debug_data(obs, corrections, guided_centroids, filename):

    outfile = h5py.File(filename, 'w')
    outfile.create_dataset('wave', data=obs.wlen_grid)
    plate_grp = outfile.create_group(str(obs.plate))
    platemjd_grp = plate_grp.create_group(str(obs.mjd))

    exp_corrections = np.mean(corrections, axis=-1)

    platemjd_grp.create_dataset('offset_x0', data=obs.offset_x0.to(u.mm).value)
    platemjd_grp.create_dataset('offset_y0', data=obs.offset_y0.to(u.mm).value)
    platemjd_grp.create_dataset('offset_x0_std', data=obs.offset_x0_std.to(u.mm).value)
    platemjd_grp.create_dataset('offset_y0_std', data=obs.offset_y0_std.to(u.mm).value)
    platemjd_grp.create_dataset('fibers', data=obs.fiber_ids)
    platemjd_grp.create_dataset('obs_seeing', data=obs.seeing.to(u.arcsec).value)
    platemjd_grp.create_dataset('obs_ha', data=obs.ha.to(u.degree).value)
    platemjd_grp.create_dataset('obs_pressure', data=obs.pressure.to(u.kPa).value)
    platemjd_grp.create_dataset('obs_temperature', data=obs.temperature.to(u.deg_C).value)

    for exp_index in range(obs.spec_file.num_exposures):
        exp_grp = platemjd_grp.create_group(str(exp_index))
        guided_x, guided_y = guided_centroids[exp_index]
        exp_guided_x = np.mean(guided_x, axis=-1)
        exp_guided_y = np.mean(guided_y, axis=-1)

        for i,fiber in enumerate(obs.fiber_ids):
            fiber_grp = exp_grp.create_group(str(fiber))

            fiber_grp.attrs['x0'] = obs.offset_x0[i].to(u.mm).value
            fiber_grp.attrs['y0'] = obs.offset_y0[i].to(u.mm).value
            fiber_grp.attrs['x0_std'] = obs.offset_x0_std[i].to(u.mm).value
            fiber_grp.attrs['y0_std'] = obs.offset_y0_std[i].to(u.mm).value
            fiber_grp.create_dataset('correction', data=exp_corrections[exp_index,i])
            fiber_grp.create_dataset('guided_x', data=exp_guided_x[i].to(u.mm).value)
            fiber_grp.create_dataset('guided_y', data=exp_guided_y[i].to(u.mm).value)

def main():
    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('-p', '--plate', type=int, default=None,
        help='plate id')
    parser.add_argument('-m', '--mjd', type=int, default=None,
        help='observation mjd')
    parser.add_argument('--output', type=str, default=None,
        help='output filename')
    parser.add_argument('--wlen-grid-steps', type=int, default=15,
        help='Number of wlen grid steps to use for correction calculation (between 3500-10500 incl.)')
    parser.add_argument('--save-guide-plots', action='store_true',
        help='Save per exposure guide plots.')
    parser.add_argument('--save-debug-data', action='store_true',
        help='Save per exposure offset data.')
    parser.add_argument('--max-obs', type=int, default=0,
        help='Maximum number of observations to calculate corrections for')
    parser.add_argument('--start-plate', type=int, default=0,
        help='Skip to start at this plate')
    parser.add_argument('--offsets', type=str, default=None,
        help='offsets input filename')
    parser.add_argument('--add-guiding-error', type=float, default=None,
        help='add specified guiding error in quadrature to psf size')
    args = parser.parse_args()

    finder = bossdata.path.Finder()
    mirror = bossdata.remote.Manager()

    if args.plate:
        # If no mjd is provided, try to guess. For plates with multiple pluggings, print list of mjds and exit.
        if args.mjd is None:
            mjd_list = bossdata.meta.get_plate_mjd_list(
                args.plate, finder=finder, mirror=mirror)
            if len(mjd_list) == 0:
                print('Plate {0:d} has not been observed with good data quality.'.format(
                    args.plate))
                return -1
            elif len(mjd_list) > 1:
                print('Plate {0:d} has been observed on MJDs {1:s}.'.format(
                    args.plate, ','.join(map(str, mjd_list))))
                print('Select one of these using the --mjd command-line argument.')
                return -1
            else:
                args.mjd = mjd_list[0]


        # Initialize observation model
        obs = tpcorr.observation.Observation(args.plate, args.mjd, wlen_grid_steps=args.wlen_grid_steps)

        if len(obs.offset_targets) > 0:
            # open output file
            filename = 'corrections-%s-%s.hdf5' % (str(args.plate), str(args.mjd)) if args.output is None else args.output
            outfile = h5py.File(filename, 'w')

            # Calculate average correction from individual exposure offsets

            avg_corrections, _, _ = obs.get_mean_correction()
            # corrections, avg_corrections, guided_centroids = obs.get_corrections()

            # Save corrections to output file
            outfile.create_dataset('wave', data=obs.wlen_grid)
            outfile.create_group(str(args.plate))
            outfile[str(args.plate)].create_group(str(args.mjd))

            for fiber, avg_correction in zip(obs.fiber_ids, avg_corrections):
                outfile.create_dataset('{}/{}/{}'.format(args.plate,args.mjd,fiber), data=avg_correction, dtype='f4')
            outfile.close()

            if args.save_debug_data:
                save_debug_data(obs, corrections, guided_centroids, 'debug_' + filename)
    else:
        # If no plate is provided, run over all plates.
        platelist = bossdata.meta.Database(platelist=True)
        # Select columns from "good" plates
        good_plates = platelist.select_all(what='PLATE,MJD', where='PLATEQUALITY="good"')

        if args.offsets:
            infile = h5py.File(args.offsets, 'r')
            wave = infile['wave'].value * u.Angstrom

        # Open output file
        outfile = h5py.File(args.output, 'w')

        max_obs = len(good_plates) if (args.max_obs == 0) else args.max_obs

        print('Found {:d} good oberservations, computing corrections for {:d}.'.format(len(good_plates), max_obs))
        print('Results will be saved to: {:s}'.format(args.output))

        # Loop over good plates
        counter = 0
        for good_plate in good_plates[::-1]:
            plate, mjd = good_plate['PLATE'], good_plate['MJD']
            # These two plates do not have any offset targets (and they're 
            # missing r2 exposures which requires causes an error when obs 
            # initialized below).
            if plate in (7334, 7336):
                continue
            # This plate has an issue with exposure names missing in header data
            # skip for now.
            if plate == 6138:
                print 'Skipping plate 6138.'
                continue
            if plate < args.start_plate:
                continue
            if max_obs and counter == max_obs:
                break
            else:
                counter += 1

            if args.offsets:
                try:
                    obs_grp = infile['{}/{}'.format(plate,mjd)]
                except KeyError, e:
                    print 'Skipping {}/{}: {}'.format(plate,mjd,e)
                    continue

                fiber_ids = obs_grp['fiber_ids'].value

                outfile_grp = outfile.create_group('{}/{}'.format(plate, mjd))
                outfile_grp.attrs['design_ha'] = obs_grp.attrs['design_ha']
                outfile_grp.attrs['design_temp'] = obs_grp.attrs['design_temp']
                outfile_grp.attrs['design_alt'] = obs_grp.attrs['design_alt'] 
                outfile_grp.attrs['ha'] = obs_grp.attrs['ha']
                outfile_grp.attrs['alt'] = obs_grp.attrs['alt']
                
                print 'Obs {}-{} design ha, obs ha, design temp: {}, {}, {}'.format(
                    plate,mjd,obs_grp.attrs['design_ha'],obs_grp.attrs['ha'],obs_grp.attrs['design_temp'])

                corrections = calculate_corrections(obs_grp, wave, add_guiding_error=args.add_guiding_error * u.arcsec)

                for fiber, correction in zip(fiber_ids, corrections):
                    # Save exposure averaged correction
                    outfile_grp.create_dataset(str(fiber), data=correction, dtype='f4')

            else:
                # Initialize observation model
                obs = tpcorr.observation.Observation(plate, mjd, wlen_grid_steps=args.wlen_grid_steps,)
                if len(obs.offset_targets) == 0:
                    continue

                # Calculate average correction from individual exposure offsets
                avg_corrections, _, _ = obs.get_mean_correction()

                # Create plate
                outfile_grp = outfile.create_group('{}/{}'.format(plate, mjd))
                outfile_grp.attrs['design_ha'] = obs.design_ha.to(u.deg).value
                outfile_grp.attrs['design_temp'] = obs.design_temp.to(u.deg_C).value
                outfile_grp.attrs['design_alt'] = obs.design_alt.to(u.deg).value
                outfile_grp.attrs['ha'] = np.mean(obs.ha.to(u.deg).value)
                outfile_grp.attrs['alt'] = np.mean(obs.alt.to(u.deg).value)
                outfile_grp.attrs['seeing'] = np.mean(obs.seeing.to(u.arcsec).value)

                # outfile_grp.attrs['num_exposures'] = obs.spec_file.num_exposures

                # outfile_grp.create_dataset('seeing', data=obs.seeing)
                # outfile_grp.create_dataset('fiber_ids', data=obs.fiber_ids)
                # outfile_grp.create_dataset('offset_x0', data=obs.offset_x0.to(u.mm).value)
                # outfile_grp.create_dataset('offset_y0', data=obs.offset_y0.to(u.mm).value)

                # for exp_index in range(obs.spec_file.num_exposures):
                #     exp_grp = outfile_grp.create_group(str(exp_index))
                #     guided_x, guided_y = obs.get_exp_centroids(exp_index)

                #     # Calculate centroid offsets for each offset target, relative to its nominal fiber center.
                #     offset = np.sqrt(
                #         (guided_x - obs.offset_x0[:, np.newaxis, np.newaxis])**2 +
                #         (guided_y - obs.offset_y0[:, np.newaxis, np.newaxis])**2) / obs.pointing.platescale
                    
                #     # Calculate centroid offsets for each offset target, relative to where its fiber center would
                #     # be if it were designed for the same wavelength as the standard stars.
                #     offset_std = np.sqrt(
                #         (guided_x - obs.offset_x0_std[:, np.newaxis, np.newaxis])**2 +
                #         (guided_y - obs.offset_y0_std[:, np.newaxis, np.newaxis])**2) / obs.pointing.platescale

                #     exp_grp.create_dataset('offset', data=offset.to(u.arcsec).value, dtype='f4')
                #     exp_grp.create_dataset('offset_std', data=offset_std.to(u.arcsec).value, dtype='f4')

                # # Loop over offset fibers
                for fiber, avg_correction in zip(obs.fiber_ids, avg_corrections):
                    # Save exposure averaged correction
                    outfile_grp.create_dataset(str(fiber), data=avg_correction, dtype='f4')
                wave = obs.wlen_grid
        outfile.create_dataset('wave', data=wave)
        outfile.close()
    

if __name__ == "__main__":
    main()

